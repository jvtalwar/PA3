{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Before training, run the following bash command!!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will allow you to go past jupyter session timeout\n",
    "#!launch-scipy-ml-gpu.sh K8S_TIMEOUT_SECONDS=43200 -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from basic_fcn import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect DataLoader objects\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a dataset data\n",
    "example = train_dataset[0]\n",
    "print(\"Training set example image file:\", train_dataset.data.iloc[0][0])\n",
    "print(\"Training set example label file:\", train_dataset.data.iloc[0][1])\n",
    "print(\"Size of the image tensor:\", example[0].size())\n",
    "print(\"Size of the one-hot target tensor:\", example[1].size())\n",
    "print(\"Size of the label tensor:\", example[2].size())\n",
    "print(example[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(sample_batched[0].size())\n",
    "    print(sample_batched[1].size())\n",
    "    print(sample_batched[2].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.unsqueeze(0)) #add unsqueeze here \n",
    "        \n",
    "epochs     = 1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "unet_model = unet(in_channels = 3, n_class=n_class)\n",
    "unet_model.apply(init_weights)\n",
    "#unet_model = torch.load('best_model')\n",
    "optimizer = optim.Adam(unet_model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory allocation: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Current memory allocation:\", torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    unet_model = unet_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory allocation: 126229504\n"
     ]
    }
   ],
   "source": [
    "print(\"Current memory allocation:\", torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 0\n",
      "Current memory allocation: 168172544\n",
      "torch.Size([1, 128, 1024, 2048])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 10.92 GiB total capacity; 10.23 GiB already allocated; 121.50 MiB free; 51.62 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mval\u001b[0;34m(epoch)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PA3/github/PA3/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup_x4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mx9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reached top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 10.92 GiB total capacity; 10.23 GiB already allocated; 121.50 MiB free; 51.62 MiB cached)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train():\n",
    "    t_losses = []\n",
    "    t_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    ious = []\n",
    "    \n",
    "    for epoch in range(0, epochs+1):\n",
    "        \n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        ts = time.time()\n",
    "        \n",
    "        numIter = 0\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        \n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            numIter +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                torch.cuda.empty_cache() \n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda()\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = unet_model(inputs)\n",
    "            del inputs\n",
    "            \n",
    "            loss = criterion(outputs, labels)            \n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "            del outputs\n",
    "            \n",
    "            indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension\n",
    "            del(speakSoftlyAndCarryABigStick)\n",
    "            \n",
    "            epoch_train_acc += pixel_acc(indexes, labels)\n",
    "            del indexes, labels\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()    \n",
    "            \n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "                  \n",
    "            #'''\n",
    "            if iter == 10:\n",
    "                break\n",
    "            #'''\n",
    "              \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Current memory allocation:\", torch.cuda.memory_allocated()) \n",
    "        \n",
    "        #torch.save(unet_model, 'best_model')\n",
    "        print()\n",
    "        \n",
    "        t_losses.append(epoch_train_loss/numIter)\n",
    "        t_accuracies.append(epoch_train_acc/numIter)\n",
    "        \n",
    "        val_loss, val_acc, iou = val(epoch)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        ious.append(iou)\n",
    "        unet_model.train()\n",
    "        \n",
    "    return t_losses, t_accuracies, val_losses, val_accuracies, ious\n",
    "\n",
    "def val(epoch):\n",
    "\n",
    "    print(\"Validation Epoch {}\".format(epoch+1))\n",
    "    \n",
    "    unet_model.eval()\n",
    "    valLoss = 0\n",
    "    valAcc = 0\n",
    "    numIter = 0\n",
    "    soMuchTension = torch.Tensor([0 for i in range(n_class)]) #intersection\n",
    "    theresATigerInTheBathroom = torch.Tensor([0 for i in range(n_class)]) #union\n",
    "    ts = time.time()\n",
    "    \n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        numIter +=1\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache() \n",
    "            inputs = X.cuda()\n",
    "            labels = Y.cuda()\n",
    "        else:\n",
    "            inputs, labels = X, Y\n",
    "        \n",
    "        print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "        outputs = unet_model(inputs)\n",
    "        print(\"HERE\")\n",
    "        valLoss += criterion(outputs, labels).item()   \n",
    "        speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "        del inputs, outputs\n",
    "        \n",
    "        indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension      \n",
    "        del speakSoftlyAndCarryABigStick\n",
    "        \n",
    "        valAcc += pixel_acc(indexes, labels)\n",
    "        theEyesHaveIt, spaceBalls = iou(indexes, labels, n_class) #intersection, union\n",
    "        del labels, indexes\n",
    "        \n",
    "        soMuchTension = soMuchTension + theEyesHaveIt\n",
    "        del theEyesHaveIt\n",
    "        \n",
    "        theresATigerInTheBathroom = theresATigerInTheBathroom + spaceBalls\n",
    "        del spaceBalls\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        #'''\n",
    "        if iter == 2:\n",
    "            break\n",
    "        #'''\n",
    "    iOweYouMoney = torch.div(soMuchTension, theresATigerInTheBathroom)\n",
    "    del soMuchTension, theresATigerInTheBathroom\n",
    "    \n",
    "    print()\n",
    "    valAcc = valAcc/numIter\n",
    "    valLoss = valLoss/numIter\n",
    "    print(\"epoch{}, validation loss: {}\".format(epoch+1, valLoss))\n",
    "    print(\"epoch{}, validation accuracy: {}\".format(epoch+1, valAcc))\n",
    "    print(\"The building IOU is: \" + str(iOweYouMoney[11].item()))\n",
    "    print(\"The traffic sign IOU is: \" + str(iOweYouMoney[20].item()))\n",
    "    print(\"The person IOU is: \" + str(iOweYouMoney[24].item()))\n",
    "    print(\"The car IOU is: \" + str(iOweYouMoney[26].item()))\n",
    "    print(\"The bicycle IOU is: \" + str(iOweYouMoney[33].item()))\n",
    "    print(\"The average IOU is: \" + str(MeanIOU(iOweYouMoney)))\n",
    "    print(\"Finish validation at epoch{}, time elapsed {}\".format(epoch+1, time.time() - ts))\n",
    "    print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "    print()\n",
    "    return valLoss, valAcc, iOweYouMoney\n",
    "    \n",
    "def test():\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    validation0 = val(-1)  # show the accuracy before training\n",
    "    '''\n",
    "    training_losses, training_accuracies, validation_losses, validation_accuracies, validation_ious = train()\n",
    "    validation_losses.insert(0, validation0[0])\n",
    "    validation_accuracies.insert(0, validation0[1])\n",
    "    validation_ious.insert(0, validation0[2])\n",
    "    validation_losses = validation_losses[:-1]\n",
    "    validation_accuracies = validation_accuracies[:-1]\n",
    "    validation_ious = validation_ious[:-1]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_losses))\n",
    "print(len(training_accuracies))\n",
    "print(len(validation_losses))\n",
    "print(len(validation_accuracies))\n",
    "print(len(validation_ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_ylabel('Losses')\n",
    "ax.set_xlabel('Epochs')\n",
    "_=ax.plot(range(0, epochs+1), training_losses,'b-',color=\"blue\",label=\"train\")\n",
    "_=ax.plot(range(0, epochs+1), validation_losses,'b-',color=\"orange\",label=\"valid\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss on training set and holdout set vs. number of epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_ylabel('Accuracies')\n",
    "ax.set_xlabel('Epochs')\n",
    "_=ax.plot(range(0, epochs+1), training_accuracies,'b-',color=\"blue\",label=\"train\")\n",
    "_=ax.plot(range(0, epochs+1), validation_accuracies,'b-',color=\"orange\",label=\"valid\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy on training set and holdout set vs. number of epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_dict = {\n",
    "    \"building\": [],\n",
    "    \"traffic sign\": [],\n",
    "    \"person\": [],\n",
    "    \"car\": [],\n",
    "    \"bicycle\": [],\n",
    "    \"average\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in validation_ious:\n",
    "    iou_dict[\"building\"].append(el[11].item())\n",
    "    iou_dict[\"traffic sign\"].append(el[20].item())\n",
    "    iou_dict[\"person\"].append(el[24].item())\n",
    "    iou_dict[\"car\"].append(el[26].item())\n",
    "    iou_dict[\"bicycle\"].append(el[33].item())\n",
    "    iou_dict[\"average\"].append(MeanIOU(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df = pd.DataFrame(iou_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_ylabel('IoUs')\n",
    "ax.set_xlabel('Epochs')\n",
    "_=ax.plot(iou_df)\n",
    "plt.legend(labels=iou_df.columns)\n",
    "plt.title(\"IoU on training set and holdout set vs. number of epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('25_epoch_training_w_iou_02_11_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
