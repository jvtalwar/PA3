{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from transfer_resnet import *\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 3\n",
    "train_dataset = CityScapesDataset(csv_file='train.csv')\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect DataLoader objects\n",
    "# print(\"Number of training examples:\", len(train_dataset))\n",
    "# print(\"Number of validation examples:\", len(val_dataset))\n",
    "# print(\"Number of test examples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Look at a dataset data\n",
    "# example = train_dataset[0]\n",
    "# print(\"Training set example image file:\", train_dataset.data.iloc[0][0])\n",
    "# print(\"Training set example label file:\", train_dataset.data.iloc[0][1])\n",
    "# print(\"Size of the image tensor:\", example[0].size())\n",
    "# print(\"Size of the one-hot target tensor:\", example[1].size())\n",
    "# print(\"Size of the label tensor:\", example[2].size())\n",
    "# print(example[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_batch, sample_batched in enumerate(train_loader):\n",
    "#     print(sample_batched[0].size())\n",
    "#     print(sample_batched[1].size())\n",
    "#     print(sample_batched[2].size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list(trans_model.children())\n",
    "# print(trans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.unsqueeze(0)) #add unsqueeze here \n",
    "        \n",
    "epochs     = 20\n",
    "learning_rate = 5e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trans_model = TransResNet(n_class=n_class, base_model = 'resnet34')\n",
    "trans_model.initialize_weights(init_weights)\n",
    "#fcn_model = torch.load('best_model')\n",
    "optimizer = optim.Adam(trans_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Epoch 0\n",
      "epoch0, validation loss: 3.606685581661406\n",
      "epoch0, validation accuracy: 6.261922731992276\n",
      "Finish validation at epoch0, time elapsed 22.672956705093384\n",
      "\n",
      "Training Epoch 1\n",
      "epoch1, iter0, loss: 3.602079391479492\n",
      "epoch1, iter100, loss: 1.4350810050964355\n",
      "Finish epoch 1, time elapsed 79.44253325462341\n",
      "\n",
      "Validation Epoch 1\n",
      "epoch1, validation loss: 1.4923184939793177\n",
      "epoch1, validation accuracy: 70.993584301725\n",
      "Finish validation at epoch1, time elapsed 24.51664924621582\n",
      "\n",
      "Training Epoch 2\n",
      "epoch2, iter0, loss: 2.6721675395965576\n",
      "epoch2, iter100, loss: 1.247492790222168\n",
      "Finish epoch 2, time elapsed 85.8407621383667\n",
      "\n",
      "Validation Epoch 2\n",
      "epoch2, validation loss: 1.1055419870785304\n",
      "epoch2, validation accuracy: 77.50795883638736\n",
      "Finish validation at epoch2, time elapsed 23.310149669647217\n",
      "\n",
      "Training Epoch 3\n",
      "epoch3, iter0, loss: 1.2561222314834595\n",
      "epoch3, iter100, loss: 0.9013659954071045\n",
      "Finish epoch 3, time elapsed 83.90204215049744\n",
      "\n",
      "Validation Epoch 3\n",
      "epoch3, validation loss: 0.9822000350270953\n",
      "epoch3, validation accuracy: 80.21361231235434\n",
      "Finish validation at epoch3, time elapsed 24.42882537841797\n",
      "\n",
      "Training Epoch 4\n",
      "epoch4, iter0, loss: 0.8125495910644531\n",
      "epoch4, iter100, loss: 0.6664603352546692\n",
      "Finish epoch 4, time elapsed 74.23279023170471\n",
      "\n",
      "Validation Epoch 4\n",
      "epoch4, validation loss: 0.9378731704893566\n",
      "epoch4, validation accuracy: 80.57072516974756\n",
      "Finish validation at epoch4, time elapsed 20.460707426071167\n",
      "\n",
      "Training Epoch 5\n",
      "epoch5, iter0, loss: 1.160744547843933\n",
      "epoch5, iter100, loss: 0.8890283703804016\n",
      "Finish epoch 5, time elapsed 73.32685446739197\n",
      "\n",
      "Validation Epoch 5\n",
      "epoch5, validation loss: 0.8728620182900202\n",
      "epoch5, validation accuracy: 80.77278814783581\n",
      "Finish validation at epoch5, time elapsed 19.865711212158203\n",
      "\n",
      "Training Epoch 6\n",
      "epoch6, iter0, loss: 0.8484129309654236\n",
      "epoch6, iter100, loss: 0.998100221157074\n",
      "Finish epoch 6, time elapsed 84.16125202178955\n",
      "\n",
      "Validation Epoch 6\n",
      "epoch6, validation loss: 0.8282134277479989\n",
      "epoch6, validation accuracy: 82.2280002767807\n",
      "Finish validation at epoch6, time elapsed 20.621187448501587\n",
      "\n",
      "Training Epoch 7\n",
      "epoch7, iter0, loss: 0.829991340637207\n",
      "epoch7, iter100, loss: 0.7763606905937195\n",
      "Finish epoch 7, time elapsed 85.80524921417236\n",
      "\n",
      "Validation Epoch 7\n",
      "epoch7, validation loss: 0.814146203654153\n",
      "epoch7, validation accuracy: 81.82872972358619\n",
      "Finish validation at epoch7, time elapsed 23.091855764389038\n",
      "\n",
      "Training Epoch 8\n",
      "epoch8, iter0, loss: 0.7654301524162292\n",
      "epoch8, iter100, loss: 0.9782471656799316\n",
      "Finish epoch 8, time elapsed 86.20663285255432\n",
      "\n",
      "Validation Epoch 8\n",
      "epoch8, validation loss: 0.7915970768247332\n",
      "epoch8, validation accuracy: 81.66622498361492\n",
      "Finish validation at epoch8, time elapsed 23.985294342041016\n",
      "\n",
      "Training Epoch 9\n",
      "epoch9, iter0, loss: 0.7475183010101318\n",
      "epoch9, iter100, loss: 1.0608285665512085\n",
      "Finish epoch 9, time elapsed 82.30109667778015\n",
      "\n",
      "Validation Epoch 9\n",
      "epoch9, validation loss: 0.8014697659583319\n",
      "epoch9, validation accuracy: 81.4392804029287\n",
      "Finish validation at epoch9, time elapsed 20.357686519622803\n",
      "\n",
      "Training Epoch 10\n",
      "epoch10, iter0, loss: 1.0129035711288452\n",
      "epoch10, iter100, loss: 0.7467517852783203\n",
      "Finish epoch 10, time elapsed 83.4141857624054\n",
      "\n",
      "Validation Epoch 10\n",
      "epoch10, validation loss: 0.7764478638058617\n",
      "epoch10, validation accuracy: 81.79139719519137\n",
      "Finish validation at epoch10, time elapsed 20.287002563476562\n",
      "\n",
      "Training Epoch 11\n",
      "epoch11, iter0, loss: 0.8541372418403625\n",
      "epoch11, iter100, loss: 0.6369259357452393\n",
      "Finish epoch 11, time elapsed 85.3268404006958\n",
      "\n",
      "Validation Epoch 11\n",
      "epoch11, validation loss: 0.8510321123259408\n",
      "epoch11, validation accuracy: 80.93304403101472\n",
      "Finish validation at epoch11, time elapsed 21.059214115142822\n",
      "\n",
      "Training Epoch 12\n",
      "epoch12, iter0, loss: 0.7818527817726135\n",
      "epoch12, iter100, loss: 1.1986955404281616\n",
      "Finish epoch 12, time elapsed 86.63465738296509\n",
      "\n",
      "Validation Epoch 12\n",
      "epoch12, validation loss: 0.835600923924219\n",
      "epoch12, validation accuracy: 81.04095888049984\n",
      "Finish validation at epoch12, time elapsed 23.3855299949646\n",
      "\n",
      "Training Epoch 13\n",
      "epoch13, iter0, loss: 0.818553626537323\n",
      "epoch13, iter100, loss: 0.6785004734992981\n",
      "Finish epoch 13, time elapsed 84.67799139022827\n",
      "\n",
      "Validation Epoch 13\n",
      "epoch13, validation loss: 0.6894243742738452\n",
      "epoch13, validation accuracy: 83.50056823883389\n",
      "Finish validation at epoch13, time elapsed 22.398022890090942\n",
      "\n",
      "Training Epoch 14\n",
      "epoch14, iter0, loss: 0.5847360491752625\n",
      "epoch14, iter100, loss: 0.5479499697685242\n",
      "Finish epoch 14, time elapsed 73.37095332145691\n",
      "\n",
      "Validation Epoch 14\n",
      "epoch14, validation loss: 0.671436281431289\n",
      "epoch14, validation accuracy: 83.63387704507174\n",
      "Finish validation at epoch14, time elapsed 22.07081437110901\n",
      "\n",
      "Training Epoch 15\n",
      "epoch15, iter0, loss: 0.7813826203346252\n",
      "epoch15, iter100, loss: 1.9166206121444702\n",
      "Finish epoch 15, time elapsed 72.62978672981262\n",
      "\n",
      "Validation Epoch 15\n",
      "epoch15, validation loss: 0.8151220991497948\n",
      "epoch15, validation accuracy: 83.0624704980934\n",
      "Finish validation at epoch15, time elapsed 20.674104690551758\n",
      "\n",
      "Training Epoch 16\n",
      "epoch16, iter0, loss: 0.6749355792999268\n",
      "epoch16, iter100, loss: 0.852837860584259\n",
      "Finish epoch 16, time elapsed 81.50590920448303\n",
      "\n",
      "Validation Epoch 16\n",
      "epoch16, validation loss: 0.7349112118993487\n",
      "epoch16, validation accuracy: 82.34782216012492\n",
      "Finish validation at epoch16, time elapsed 22.602442502975464\n",
      "\n",
      "Training Epoch 17\n",
      "epoch17, iter0, loss: 0.7832229137420654\n",
      "epoch17, iter100, loss: 0.7564749121665955\n",
      "Finish epoch 17, time elapsed 86.0143232345581\n",
      "\n",
      "Validation Epoch 17\n",
      "epoch17, validation loss: 0.7893824179967245\n",
      "epoch17, validation accuracy: 81.02720031580743\n",
      "Finish validation at epoch17, time elapsed 23.68751311302185\n",
      "\n",
      "Training Epoch 18\n",
      "epoch18, iter0, loss: 0.7248223423957825\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    trans_model = trans_model.cuda()\n",
    "    \n",
    "def train():\n",
    "    t_losses = []\n",
    "    t_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        ts = time.time()\n",
    "        \n",
    "        numIter = 0\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        \n",
    "        for iter, (X, _, Y) in enumerate(train_loader):\n",
    "            numIter +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda()\n",
    "#                 oneHotLabels = tar.cuda()\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = trans_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "#             if iter > 0:\n",
    "#                 print('Batch #' + str(iter) + ' training error: ' + str(loss.item()))\n",
    "            \n",
    "            speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "            indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension\n",
    "            epoch_train_acc += pixel_acc(indexes, labels) \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "            #'''\n",
    "            if iter == 100:\n",
    "                break\n",
    "            #'''\n",
    "            \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        del inputs, labels, outputs, loss, indexes, speakSoftlyAndCarryABigStick\n",
    "        torch.cuda.empty_cache()     \n",
    "        #torch.save(fcn_model, 'best_model')\n",
    "        print()\n",
    "        \n",
    "        t_losses.append(epoch_train_loss/numIter)\n",
    "        t_accuracies.append(epoch_train_acc/numIter)\n",
    "        \n",
    "        val_loss, val_acc = val(epoch)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        trans_model.train()\n",
    "    return t_losses, t_accuracies, val_losses, val_accuracies\n",
    "\n",
    "def val(epoch):\n",
    "    print(\"Validation Epoch {}\".format(epoch))\n",
    "    trans_model.eval()\n",
    "    #Complete this function - Calculate loss, accuracy and IoU for every epoch\n",
    "    valLoss = 0\n",
    "    valAcc = 0\n",
    "    numIter = 0\n",
    "    ts = time.time()\n",
    "    for iter, (X, _, Y) in enumerate(val_loader):\n",
    "            numIter +=1\n",
    "            if use_gpu:\n",
    "                torch.cuda.empty_cache() \n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda()\n",
    "#                 oneHotLabels = tar.cuda()\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "            \n",
    "            outputs = trans_model(inputs)\n",
    "            valLoss += criterion(outputs, labels).item()   \n",
    "            \n",
    "            speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "            indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension\n",
    "            \n",
    "            '''\n",
    "            #Only use for one batch\n",
    "            \n",
    "            print(\"Model output size (not one-hot encoded):\", indexes.size())\n",
    "            print(indexes)\n",
    "            print(\"Original label size (not one-hot encoded):\", labels.size())\n",
    "            print(labels)\n",
    "            print()\n",
    "            print(\"Model output size for channel 30 (one-hot encoded):\", goGoGadgetSkis.size())\n",
    "            print(goGoGadgetSkis[0][30])\n",
    "            print(\"Original label size for channel 30 (one-hot encoded):\", oneHotLabels.size())\n",
    "            print(oneHotLabels[0][30])\n",
    "            print()\n",
    "            '''\n",
    "\n",
    "            valAcc += pixel_acc(indexes, labels)        \n",
    "            \n",
    "            #manage memory again...\n",
    "            del inputs, labels, outputs, indexes, speakSoftlyAndCarryABigStick\n",
    "            torch.cuda.empty_cache()            \n",
    "            \n",
    "            #'''\n",
    "            if iter == 20:\n",
    "                break\n",
    "            #'''\n",
    "            \n",
    "    valAcc = valAcc/numIter\n",
    "    valLoss = valLoss/numIter\n",
    "    print(\"epoch{}, validation loss: {}\".format(epoch, valLoss))\n",
    "    print(\"epoch{}, validation accuracy: {}\".format(epoch, valAcc))\n",
    "    print(\"Finish validation at epoch{}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "    print()\n",
    "    return valLoss, valAcc\n",
    "    \n",
    "def test():\n",
    "    #Complete this function - Calculate accuracy and IoU \n",
    "    # Make sure to include a softmax after the output from your model\n",
    "    speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    val(0)  # show the accuracy before training\n",
    "    training_losses, training_accuracies, validation_losses, validation_accuracies = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_losses)\n",
    "print(training_accuracies)\n",
    "print(validation_losses)\n",
    "print(validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import save as model_save\n",
    "\n",
    "\n",
    "fname = os.path.join('resnet34_epoch' + str(epochs) + '_lr' + \"{:.0e}\".format(learning_rate))\n",
    "model_save(trans_model, os.path.join('Saved Models', fname +'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_ylabel('Losses')\n",
    "ax.set_xlabel('Epochs')\n",
    "_=ax.plot(range(1, epochs+1), training_losses,'b-',color=\"blue\",label=\"train\")\n",
    "_=ax.plot(range(1, epochs+1), validation_losses,'b-',color=\"orange\",label=\"valid\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss on training set and holdout set vs. number of epochs\")\n",
    "plt.savefig(os.path.join('Plots', fname + '_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.set_ylabel('Accuracies')\n",
    "ax.set_xlabel('Epochs')\n",
    "_=ax.plot(range(1, epochs+1), training_accuracies,'b-',color=\"blue\",label=\"train\")\n",
    "_=ax.plot(range(1, epochs+1), validation_accuracies,'b-',color=\"orange\",label=\"valid\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy on training set and holdout set vs. number of epochs\")\n",
    "plt.savefig(os.path.join('Plots', fname + '_accuracy.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('resnet18_epoch' + str(epochs) + '_lr' + \"{:.0e}\".format(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
