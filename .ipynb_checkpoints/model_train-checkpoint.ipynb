{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Before training, run the following bash command!!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will allow you to go past jupyter session timeout\n",
    "#!launch-scipy-ml-gpu.sh K8S_TIMEOUT_SECONDS=43200 -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "# from basic_fcn import *\n",
    "from transfer_resnet import *\n",
    "from dataloader2 import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch = 4\n",
    "val_batch = 4\n",
    "test_batch = 1\n",
    "train_dataset = CityScapesDataset(csv_file='train.csv', transforms = ['hflip', 'rotation'], resize_factor = 0.5)\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=training_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=val_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=test_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.unsqueeze(0)) #add unsqueeze here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train0(model, loss_fn, weights=None):\n",
    "    print(\"Training Epoch 0\")\n",
    "    \n",
    "    model.eval()\n",
    "    trainLoss = 0\n",
    "    trainAcc = 0\n",
    "    numIter = 0\n",
    "    soMuchTension = torch.Tensor([0 for i in range(n_class)]) #intersection\n",
    "    theresATigerInTheBathroom = torch.Tensor([0 for i in range(n_class)]) #union\n",
    "    ts = time.time()\n",
    "    \n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        numIter +=1\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache() \n",
    "            inputs = X.cuda()\n",
    "            labels = Y.cuda()\n",
    "        else:\n",
    "            inputs, one_hot_labels, labels = X, tar, Y\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if weights == None:\n",
    "            trainLoss += loss_fn(outputs, labels).item()\n",
    "        \n",
    "        else:\n",
    "            trainLoss += weighted_cross_entropy(outputs, labels, weights).item()\n",
    "        \n",
    "        speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "        del inputs, outputs\n",
    "        \n",
    "        indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension      \n",
    "        del speakSoftlyAndCarryABigStick\n",
    "        \n",
    "        trainAcc += pixel_acc(indexes, labels)\n",
    "        \n",
    "        theEyesHaveIt, spaceBalls = iou(indexes, labels, n_class) #intersection, union\n",
    "        del labels, indexes\n",
    "        \n",
    "        soMuchTension = soMuchTension + theEyesHaveIt\n",
    "        del theEyesHaveIt\n",
    "        \n",
    "        theresATigerInTheBathroom = theresATigerInTheBathroom + spaceBalls\n",
    "        del spaceBalls\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #'''\n",
    "        if iter == 2:\n",
    "            break\n",
    "        #'''\n",
    "        \n",
    "    iOweYouMoney = torch.div(soMuchTension, theresATigerInTheBathroom)\n",
    "    del soMuchTension, theresATigerInTheBathroom\n",
    "    \n",
    "    print()\n",
    "    trainAcc = trainAcc/numIter\n",
    "    trainLoss = trainLoss/numIter\n",
    "    print(\"epoch0, train loss: {}\".format(trainLoss))\n",
    "    print(\"epoch0, train accuracy: {}\".format(trainAcc))\n",
    "    print(\"The building IOU is: \" + str(iOweYouMoney[11].item()))\n",
    "    print(\"The traffic sign IOU is: \" + str(iOweYouMoney[20].item()))\n",
    "    print(\"The person IOU is: \" + str(iOweYouMoney[24].item()))\n",
    "    print(\"The car IOU is: \" + str(iOweYouMoney[26].item()))\n",
    "    print(\"The bicycle IOU is: \" + str(iOweYouMoney[33].item()))\n",
    "    print(\"The average IOU is: \" + str(MeanIOU(iOweYouMoney)))\n",
    "    print(\"Finish validation at epoch0, time elapsed {}\".format(time.time() - ts))\n",
    "    print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "    print()\n",
    "    return trainLoss, trainAcc, iOweYouMoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, loss_fn, epoch, weights=None):\n",
    "\n",
    "    print(\"Validation Epoch {}\".format(epoch))\n",
    "    \n",
    "    model.eval()\n",
    "    valLoss = 0\n",
    "    valAcc = 0\n",
    "    numIter = 0\n",
    "    soMuchTension = torch.Tensor([0 for i in range(n_class)]) #intersection\n",
    "    theresATigerInTheBathroom = torch.Tensor([0 for i in range(n_class)]) #union\n",
    "    ts = time.time()\n",
    "    \n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        numIter +=1\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache() \n",
    "            inputs = X.cuda()\n",
    "            labels = Y.cuda()\n",
    "        else:\n",
    "            inputs, one_hot_labels, labels = X, tar, Y\n",
    "            \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if weights == None:\n",
    "            valLoss += loss_fn(outputs, labels).item()\n",
    "        \n",
    "        else:\n",
    "            valLoss += weighted_cross_entropy(outputs, labels, weights).item()\n",
    "        \n",
    "        speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "        del inputs, outputs\n",
    "        \n",
    "        indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension      \n",
    "        del speakSoftlyAndCarryABigStick\n",
    "        \n",
    "        valAcc += pixel_acc(indexes, labels)\n",
    "        theEyesHaveIt, spaceBalls = iou(indexes, labels, n_class) #intersection, union\n",
    "        del labels, indexes\n",
    "        \n",
    "        soMuchTension = soMuchTension + theEyesHaveIt\n",
    "        del theEyesHaveIt\n",
    "        \n",
    "        theresATigerInTheBathroom = theresATigerInTheBathroom + spaceBalls\n",
    "        del spaceBalls\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        #'''\n",
    "        if iter == 2:\n",
    "            break\n",
    "        #'''\n",
    "        \n",
    "    iOweYouMoney = torch.div(soMuchTension, theresATigerInTheBathroom)\n",
    "    del soMuchTension, theresATigerInTheBathroom\n",
    "    \n",
    "    print()\n",
    "    valAcc = valAcc/numIter\n",
    "    valLoss = valLoss/numIter\n",
    "    print(\"epoch{}, validation loss: {}\".format(epoch, valLoss))\n",
    "    print(\"epoch{}, validation accuracy: {}\".format(epoch, valAcc))\n",
    "    print(\"The building IOU is: \" + str(iOweYouMoney[11].item()))\n",
    "    print(\"The traffic sign IOU is: \" + str(iOweYouMoney[20].item()))\n",
    "    print(\"The person IOU is: \" + str(iOweYouMoney[24].item()))\n",
    "    print(\"The car IOU is: \" + str(iOweYouMoney[26].item()))\n",
    "    print(\"The bicycle IOU is: \" + str(iOweYouMoney[33].item()))\n",
    "    print(\"The average IOU is: \" + str(MeanIOU(iOweYouMoney)))\n",
    "    print(\"Finish validation at epoch{}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "    print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "    print()\n",
    "    return valLoss, valAcc, iOweYouMoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, epochs, patience, weights=None):\n",
    "    t_losses = []\n",
    "    t_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    ious = []\n",
    "    \n",
    "    e_stop = False\n",
    "    best_model = None\n",
    "    stop = EarlyStop(patience)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        ts = time.time()\n",
    "        \n",
    "        numIter = 0\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        \n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            numIter +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                torch.cuda.empty_cache() \n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda()\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            del inputs\n",
    "            \n",
    "            if weights == None:\n",
    "                loss = loss_fn(outputs, labels)         \n",
    "                epoch_train_loss += loss.item()\n",
    "        \n",
    "            else:\n",
    "                loss = weighted_cross_entropy(outputs, labels, weights)\n",
    "                epoch_train_loss += loss.item()\n",
    "            \n",
    "            speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "            del outputs\n",
    "            \n",
    "            indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension\n",
    "            del(speakSoftlyAndCarryABigStick)\n",
    "            \n",
    "            epoch_train_acc += pixel_acc(indexes, labels)\n",
    "            del indexes, labels\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()    \n",
    "            \n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "                  \n",
    "            #'''\n",
    "            if iter == 10:\n",
    "                break\n",
    "            #'''\n",
    "              \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"epoch{}, training accuracy: {}\".format(epoch, epoch_train_acc/numIter))\n",
    "        print(\"Current memory allocation:\", torch.cuda.memory_allocated()) \n",
    "        \n",
    "        print()\n",
    "        \n",
    "        t_losses.append(epoch_train_loss/numIter)\n",
    "        t_accuracies.append(epoch_train_acc/numIter)\n",
    "        \n",
    "        val_loss, val_acc, iou = val(model, loss_fn, epoch)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        ious.append(iou)\n",
    "        \n",
    "        e_stop, best_model = stop(val_loss, model)\n",
    "        if e_stop:\n",
    "            torch.save(best_model.state_dict(), join(saving_directory, '{}.pt'.format(best_model_name)))\n",
    "            print(\"Early stopping at:\", epoch)\n",
    "            break\n",
    "            \n",
    "        model.train()\n",
    "    \n",
    "    if not e_stop:\n",
    "        torch.save(best_model.state_dict(), join(saving_directory, '{}.pt'.format(best_model_name)))\n",
    "        \n",
    "    return t_losses, t_accuracies, val_losses, val_accuracies, ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #3 'weight' in call to _thnn_nll_loss2d_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d78936f28795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Establish baseline metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrain_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mvalidation_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# show the accuracy before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d390f34ee188>\u001b[0m in \u001b[0;36mtrain0\u001b[0;34m(model, loss_fn, weights)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtrainLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'weight' in call to _thnn_nll_loss2d_forward"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # Update this for your model\n",
    "    res_type = 'resnet18'\n",
    "    best_model_name = res_type + \"_model_weighted\"\n",
    "    saving_directory = 'Kian' \n",
    "    \n",
    "    epochs = 50\n",
    "    be_patient = 5\n",
    "    \n",
    "    # Set up class weights to potentially use\n",
    "    class_weights = torch.FloatTensor(1/np.load('total_pixel_weights.npy'))\n",
    "    class_weights = class_weights/class_weights.sum() # * n_class\n",
    "    class_weights = class_weights.cuda()\n",
    "    \n",
    "    # Non-weighted vs weighted loss definition\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    weighted_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion = weighted_criterion \n",
    "    \n",
    "    # Build model\n",
    "    trans_model = TransResNet(n_class=n_class, base_model=res_type)\n",
    "#     trans_model.apply(init_weights)\n",
    "    trans_model.initialize_weights(init_weights)\n",
    "    #trans_model = torch.load('best_model')  # For when we have a best model to test\n",
    "    optimizer = optim.Adam(trans_model.parameters(), lr=5e-3)\n",
    "    \n",
    "    # Move model to gpu\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        trans_model = trans_model.cuda()\n",
    "    \n",
    "    # Establish baseline metrics\n",
    "    train_0 = train0(trans_model, criterion)\n",
    "    validation_0 = val(trans_model, criterion, 0)  # show the accuracy before training\n",
    "    \n",
    "    # Train for epochs with patience\n",
    "    training_losses, training_accuracies, validation_losses, validation_accuracies, validation_ious = train(trans_model, criterion, epochs, be_patient)\n",
    "        \n",
    "    # Add in the baseline\n",
    "    training_losses.insert(0, train_0[0])\n",
    "    training_accuracies.insert(0, train_0[1])    \n",
    "    validation_losses.insert(0, validation_0[0])\n",
    "    validation_accuracies.insert(0, validation_0[1])\n",
    "    validation_ious.insert(0, validation_0[2])\n",
    "    \n",
    "    # Plot loss and save fig\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('Losses')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(range(0, epochs+1), training_losses,'b-',color=\"blue\",label=\"train\")\n",
    "    _=ax.plot(range(0, epochs+1), validation_losses,'b-',color=\"orange\",label=\"valid\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss on training set and holdout set vs. number of epochs\")\n",
    "    plt.savefig(join(saving_directory, '{}_loss.png'.format(best_model_name)))\n",
    "    \n",
    "    # Plot loss and save fig\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('Accuracies')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(range(0, epochs+1), training_accuracies,'b-',color=\"blue\",label=\"train\")\n",
    "    _=ax.plot(range(0, epochs+1), validation_accuracies,'b-',color=\"orange\",label=\"valid\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy on training set and holdout set vs. number of epochs\")\n",
    "    plt.savefig(join(saving_directory,'{}_accuracy.png'.format(best_model_name)))\n",
    "    \n",
    "    # Build pd dataframe\n",
    "    iou_dict = {\n",
    "    \"building\": [],\n",
    "    \"traffic sign\": [],\n",
    "    \"person\": [],\n",
    "    \"car\": [],\n",
    "    \"bicycle\": [],\n",
    "    \"average\": []\n",
    "    }\n",
    "    \n",
    "    for el in validation_ious:\n",
    "        iou_dict[\"building\"].append(el[11].item())\n",
    "        iou_dict[\"traffic sign\"].append(el[20].item())\n",
    "        iou_dict[\"person\"].append(el[24].item())\n",
    "        iou_dict[\"car\"].append(el[26].item())\n",
    "        iou_dict[\"bicycle\"].append(el[33].item())\n",
    "        iou_dict[\"average\"].append(MeanIOU(el))\n",
    "        \n",
    "    iou_df = pd.DataFrame(iou_dict)\n",
    "    \n",
    "    # Plot IoUs\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('IoUs')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(iou_df)\n",
    "    plt.legend(labels=iou_df.columns)\n",
    "    plt.title(\"Specific IoUs over Epochs\")\n",
    "    plt.savefig(join(saving_directory, '{}_IoU.png'.format(best_model_name)))\n",
    "    \n",
    "    # Add losses and accuracies\n",
    "    iou_df['training_losses'] = training_losses\n",
    "    iou_df['training_accuracy'] = training_accuracies\n",
    "    iou_df['validation_losses'] = validation_losses\n",
    "    iou_df['validation_accuracy'] = validation_accuracies\n",
    "    \n",
    "    # Save a csv\n",
    "    iou_df.to_csv(join(saving_directory, '{}.csv'.format(best_model_name)))\n",
    "    \n",
    "    # Test image with overlayed classified labels\n",
    "    test_model = TransResNet(n_class=n_class, base_model=res_type)\n",
    "    test_model.load_state_dict(torch.load(join(saving_directory, '{}.pt'.format(best_model_name))))\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        test_image = sample_batched[0]\n",
    "        break\n",
    "        \n",
    "    test_output = test_model(test_image)\n",
    "    log_output = F.softmax(test_output, dim = 1)\n",
    "    out_labels = torch.argmax(log_output, dim = 1).squeeze().numpy()\n",
    "    test_img_np = data2img(test_image.squeeze(0))\n",
    "    image_overlay(test_img_np, out_labels, join(saving_directory, '{}_ovelayed.png'.format(best_model_name)), n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
