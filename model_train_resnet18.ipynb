{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Before training, run the following bash command!!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will allow you to go past jupyter session timeout\n",
    "#!launch-scipy-ml-gpu.sh K8S_TIMEOUT_SECONDS=43200 -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "# from basic_fcn import *\n",
    "from transfer_resnet import *\n",
    "# from dataloader import *\n",
    "from dataloader2 import *\n",
    "from utils import *\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch = 4\n",
    "val_batch = 4\n",
    "test_batch = 1\n",
    "train_dataset = CityScapesDataset(csv_file='train.csv', transforms = ['hflip', 'rotation'], resize_factor = 0.5)\n",
    "val_dataset = CityScapesDataset(csv_file='val.csv')\n",
    "test_dataset = CityScapesDataset(csv_file='test.csv')\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=training_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=val_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=test_batch,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(m.bias.data.unsqueeze(0)) #add unsqueeze here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train0(model, loss_fn, weights=None):\n",
    "    print(\"Training Epoch 0\")\n",
    "    \n",
    "    model.eval()\n",
    "    trainLoss = 0\n",
    "    trainAcc = 0\n",
    "    numIter = 0\n",
    "    soMuchTension = torch.Tensor([0 for i in range(n_class)]) #intersection\n",
    "    theresATigerInTheBathroom = torch.Tensor([0 for i in range(n_class)]) #union\n",
    "    ts = time.time()\n",
    "    \n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        numIter +=1\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache() \n",
    "            inputs = X.cuda()\n",
    "            labels = Y.cuda()\n",
    "        else:\n",
    "            inputs, one_hot_labels, labels = X, tar, Y\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if weights == None:\n",
    "            trainLoss += loss_fn(outputs, labels).item()\n",
    "        \n",
    "        else:\n",
    "            trainLoss += weighted_cross_entropy(outputs, labels, weights).item()\n",
    "        \n",
    "        speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "        del inputs, outputs\n",
    "        \n",
    "        indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension      \n",
    "        del speakSoftlyAndCarryABigStick\n",
    "        \n",
    "        trainAcc += pixel_acc(indexes, labels)\n",
    "        \n",
    "        theEyesHaveIt, spaceBalls = iou(indexes, labels, n_class) #intersection, union\n",
    "        del labels, indexes\n",
    "        \n",
    "        soMuchTension = soMuchTension + theEyesHaveIt\n",
    "        del theEyesHaveIt\n",
    "        \n",
    "        theresATigerInTheBathroom = theresATigerInTheBathroom + spaceBalls\n",
    "        del spaceBalls\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        '''\n",
    "        if iter == 2:\n",
    "            break\n",
    "        '''\n",
    "        \n",
    "    iOweYouMoney = torch.div(soMuchTension, theresATigerInTheBathroom)\n",
    "    del soMuchTension, theresATigerInTheBathroom\n",
    "    \n",
    "    print()\n",
    "    trainAcc = trainAcc/numIter\n",
    "    trainLoss = trainLoss/numIter\n",
    "    print(\"epoch0, train loss: {}\".format(trainLoss))\n",
    "    print(\"epoch0, train accuracy: {}\".format(trainAcc))\n",
    "    print(\"The building IOU is: \" + str(iOweYouMoney[11].item()))\n",
    "    print(\"The traffic sign IOU is: \" + str(iOweYouMoney[20].item()))\n",
    "    print(\"The person IOU is: \" + str(iOweYouMoney[24].item()))\n",
    "    print(\"The car IOU is: \" + str(iOweYouMoney[26].item()))\n",
    "    print(\"The bicycle IOU is: \" + str(iOweYouMoney[33].item()))\n",
    "    print(\"The average IOU is: \" + str(MeanIOU(iOweYouMoney)))\n",
    "    print(\"Finish validation at epoch0, time elapsed {}\".format(time.time() - ts))\n",
    "    print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "    print()\n",
    "    return trainLoss, trainAcc, iOweYouMoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, loss_fn, epoch, weights=None):\n",
    "\n",
    "    print(\"Validation Epoch {}\".format(epoch))\n",
    "    \n",
    "    model.eval()\n",
    "    valLoss = 0\n",
    "    valAcc = 0\n",
    "    numIter = 0\n",
    "    soMuchTension = torch.Tensor([0 for i in range(n_class)]) #intersection\n",
    "    theresATigerInTheBathroom = torch.Tensor([0 for i in range(n_class)]) #union\n",
    "    ts = time.time()\n",
    "    \n",
    "    for iter, (X, tar, Y) in enumerate(val_loader):\n",
    "        numIter +=1\n",
    "        if use_gpu:\n",
    "            torch.cuda.empty_cache() \n",
    "            inputs = X.cuda()\n",
    "            labels = Y.cuda()\n",
    "        else:\n",
    "            inputs, one_hot_labels, labels = X, tar, Y\n",
    "            \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if weights == None:\n",
    "            valLoss += loss_fn(outputs, labels).item()\n",
    "        \n",
    "        else:\n",
    "            valLoss += weighted_cross_entropy(outputs, labels, weights).item()\n",
    "        \n",
    "        speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "        del inputs, outputs\n",
    "        \n",
    "        indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension      \n",
    "        del speakSoftlyAndCarryABigStick\n",
    "        \n",
    "        valAcc += pixel_acc(indexes, labels)\n",
    "        theEyesHaveIt, spaceBalls = iou(indexes, labels, n_class) #intersection, union\n",
    "        del labels, indexes\n",
    "        \n",
    "        soMuchTension = soMuchTension + theEyesHaveIt\n",
    "        del theEyesHaveIt\n",
    "        \n",
    "        theresATigerInTheBathroom = theresATigerInTheBathroom + spaceBalls\n",
    "        del spaceBalls\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        '''\n",
    "        if iter == 2:\n",
    "            break\n",
    "        '''\n",
    "        \n",
    "    iOweYouMoney = torch.div(soMuchTension, theresATigerInTheBathroom)\n",
    "    del soMuchTension, theresATigerInTheBathroom\n",
    "    \n",
    "    print()\n",
    "    valAcc = valAcc/numIter\n",
    "    valLoss = valLoss/numIter\n",
    "    print(\"epoch{}, validation loss: {}\".format(epoch, valLoss))\n",
    "    print(\"epoch{}, validation accuracy: {}\".format(epoch, valAcc))\n",
    "    print(\"The building IOU is: \" + str(iOweYouMoney[11].item()))\n",
    "    print(\"The traffic sign IOU is: \" + str(iOweYouMoney[20].item()))\n",
    "    print(\"The person IOU is: \" + str(iOweYouMoney[24].item()))\n",
    "    print(\"The car IOU is: \" + str(iOweYouMoney[26].item()))\n",
    "    print(\"The bicycle IOU is: \" + str(iOweYouMoney[33].item()))\n",
    "    print(\"The average IOU is: \" + str(MeanIOU(iOweYouMoney)))\n",
    "    print(\"Finish validation at epoch{}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "    print(\"Current memory allocation:\", torch.cuda.memory_allocated())\n",
    "    print()\n",
    "    return valLoss, valAcc, iOweYouMoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, epochs, patience, weights=None):\n",
    "    t_losses = []\n",
    "    t_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    ious = []\n",
    "    \n",
    "    e_stop = False\n",
    "    best_model = None\n",
    "    stop = EarlyStop(patience)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        ts = time.time()\n",
    "        \n",
    "        numIter = 0\n",
    "        epoch_train_loss = 0\n",
    "        epoch_train_acc = 0\n",
    "        \n",
    "        for iter, (X, tar, Y) in enumerate(train_loader):\n",
    "            numIter +=1\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_gpu:\n",
    "                torch.cuda.empty_cache() \n",
    "                inputs = X.cuda() # Move your inputs onto the gpu\n",
    "                labels = Y.cuda()\n",
    "            else:\n",
    "                inputs, labels = X, Y # Unpack variables into inputs and labels\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            del inputs\n",
    "            \n",
    "            if weights == None:\n",
    "                loss = loss_fn(outputs, labels)         \n",
    "                epoch_train_loss += loss.item()\n",
    "        \n",
    "            else:\n",
    "                loss = weighted_cross_entropy(outputs, labels, weights)\n",
    "                epoch_train_loss += loss.item()\n",
    "            \n",
    "            speakSoftlyAndCarryABigStick = F.softmax(outputs, dim = 1) #softmax along the number of class dimension\n",
    "            del outputs\n",
    "            \n",
    "            indexes = torch.argmax(speakSoftlyAndCarryABigStick, dim = 1) #get the argmax along the channel dimension\n",
    "            del(speakSoftlyAndCarryABigStick)\n",
    "            \n",
    "            epoch_train_acc += pixel_acc(indexes, labels)\n",
    "            del indexes, labels\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()    \n",
    "            \n",
    "            if iter % 100 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "                  \n",
    "            '''\n",
    "            if iter == 10:\n",
    "                break\n",
    "            '''\n",
    "              \n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"epoch{}, training accuracy: {}\".format(epoch, epoch_train_acc/numIter))\n",
    "        print(\"Current memory allocation:\", torch.cuda.memory_allocated()) \n",
    "        \n",
    "        print()\n",
    "        \n",
    "        t_losses.append(epoch_train_loss/numIter)\n",
    "        t_accuracies.append(epoch_train_acc/numIter)\n",
    "        \n",
    "        val_loss, val_acc, iou = val(model, loss_fn, epoch)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        ious.append(iou)\n",
    "        \n",
    "        e_stop, best_model = stop(val_loss, model)\n",
    "        if e_stop:\n",
    "            torch.save(best_model.state_dict(), join(saving_directory, '{}.pt'.format(best_model_name)))\n",
    "            print(\"Early stopping at:\", epoch)\n",
    "            break\n",
    "            \n",
    "        model.train()\n",
    "    \n",
    "    if not e_stop:\n",
    "        torch.save(best_model.state_dict(), join(saving_directory, '{}.pt'.format(best_model_name)))\n",
    "        \n",
    "    return t_losses, t_accuracies, val_losses, val_accuracies, ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n",
      "\n",
      "epoch0, train loss: 3.70868985748291\n",
      "epoch0, train accuracy: 0.6421075171205444\n",
      "The building IOU is: 0.0\n",
      "The traffic sign IOU is: 0.0\n",
      "The person IOU is: 0.0\n",
      "The car IOU is: 0.002416783943772316\n",
      "The bicycle IOU is: 0.0002883077540900558\n",
      "The average IOU is: 0.0006669411207419193\n",
      "Finish validation at epoch0, time elapsed 132.30797147750854\n",
      "Current memory allocation: 61412352\n",
      "\n",
      "Validation Epoch 0\n",
      "\n",
      "epoch0, validation loss: 3.7086898975372313\n",
      "epoch0, validation accuracy: 0.6406247693926558\n",
      "The building IOU is: 0.0\n",
      "The traffic sign IOU is: 0.0\n",
      "The person IOU is: 0.0\n",
      "The car IOU is: 0.002416783943772316\n",
      "The bicycle IOU is: 0.0002883077540900558\n",
      "The average IOU is: 0.0006669410716770735\n",
      "Finish validation at epoch0, time elapsed 156.88761591911316\n",
      "Current memory allocation: 61412352\n",
      "\n",
      "Training Epoch 1\n",
      "epoch1, iter0, loss: 3.7664942741394043\n",
      "epoch1, iter100, loss: 1.5589193105697632\n",
      "epoch1, iter200, loss: 1.1224220991134644\n",
      "epoch1, iter300, loss: 0.9556676745414734\n",
      "epoch1, iter400, loss: 1.129686713218689\n",
      "epoch1, iter500, loss: 0.8872473239898682\n",
      "epoch1, iter600, loss: 0.9613407254219055\n",
      "epoch1, iter700, loss: 1.1051403284072876\n",
      "Finish epoch 1, time elapsed 427.858891248703\n",
      "epoch1, training accuracy: 71.73687507391818\n",
      "Current memory allocation: 110416896\n",
      "\n",
      "Validation Epoch 1\n",
      "\n",
      "epoch1, validation loss: 1.1545961804389953\n",
      "epoch1, validation accuracy: 76.37193122757242\n",
      "The building IOU is: 0.6082062721252441\n",
      "The traffic sign IOU is: 0.005680715199559927\n",
      "The person IOU is: 0.2582225799560547\n",
      "The car IOU is: 0.555621325969696\n",
      "The bicycle IOU is: 0.19781309366226196\n",
      "The average IOU is: 0.19632873551553962\n",
      "Finish validation at epoch1, time elapsed 166.42911672592163\n",
      "Current memory allocation: 110416896\n",
      "\n",
      "Going down no need to do anything... good job!\n",
      "Training Epoch 2\n",
      "epoch2, iter0, loss: 2.333742141723633\n",
      "epoch2, iter100, loss: 0.9470376372337341\n",
      "epoch2, iter200, loss: 0.7402051687240601\n",
      "epoch2, iter300, loss: 0.9984575510025024\n",
      "epoch2, iter400, loss: 0.9381036162376404\n",
      "epoch2, iter500, loss: 1.0902653932571411\n",
      "epoch2, iter600, loss: 0.8985635042190552\n",
      "epoch2, iter700, loss: 0.5734976530075073\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # Update this for your model\n",
    "    res_type = 'resnet18'\n",
    "    best_model_name = res_type + \"_model\"\n",
    "    saving_directory = 'Kian' \n",
    "    \n",
    "    epochs = 50\n",
    "    be_patient = 5\n",
    "    \n",
    "    # Set up class weights to potentially use\n",
    "    class_weights = torch.FloatTensor(1/np.load('total_pixel_weights.npy'))\n",
    "    class_weights = class_weights/class_weights.sum() # * n_class\n",
    "#     class_weights = class_weights.cuda()\n",
    "    \n",
    "    # Non-weighted vs weighted loss definition\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    weighted_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#     criterion = weighted_criterion \n",
    "    \n",
    "    # Build model\n",
    "    trans_model = TransResNet(n_class=n_class, base_model=res_type)\n",
    "#     trans_model.apply(init_weights)\n",
    "    trans_model.initialize_weights(init_weights)\n",
    "    #trans_model = torch.load('best_model')  # For when we have a best model to test\n",
    "    optimizer = optim.Adam(trans_model.parameters(), lr=5e-3)\n",
    "    \n",
    "    # Move model to gpu\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        trans_model = trans_model.cuda()\n",
    "    \n",
    "    # Establish baseline metrics\n",
    "    train_0 = train0(trans_model, criterion)\n",
    "    validation_0 = val(trans_model, criterion, 0)  # show the accuracy before training\n",
    "    \n",
    "    # Train for epochs with patience\n",
    "    training_losses, training_accuracies, validation_losses, validation_accuracies, validation_ious = train(trans_model, criterion, epochs, be_patient)\n",
    "        \n",
    "    # Add in the baseline\n",
    "    training_losses.insert(0, train_0[0])\n",
    "    training_accuracies.insert(0, train_0[1])    \n",
    "    validation_losses.insert(0, validation_0[0])\n",
    "    validation_accuracies.insert(0, validation_0[1])\n",
    "    validation_ious.insert(0, validation_0[2])\n",
    "    \n",
    "    # Plot loss and save fig\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('Losses')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(range(0, epochs+1), training_losses,'b-',color=\"blue\",label=\"train\")\n",
    "    _=ax.plot(range(0, epochs+1), validation_losses,'b-',color=\"orange\",label=\"valid\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss on training set and holdout set vs. number of epochs\")\n",
    "    plt.savefig(join(saving_directory, '{}_loss.png'.format(best_model_name)))\n",
    "    \n",
    "    # Plot loss and save fig\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('Accuracies')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(range(0, epochs+1), training_accuracies,'b-',color=\"blue\",label=\"train\")\n",
    "    _=ax.plot(range(0, epochs+1), validation_accuracies,'b-',color=\"orange\",label=\"valid\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy on training set and holdout set vs. number of epochs\")\n",
    "    plt.savefig(join(saving_directory,'{}_accuracy.png'.format(best_model_name)))\n",
    "    \n",
    "    # Build pd dataframe\n",
    "    iou_dict = {\n",
    "    \"building\": [],\n",
    "    \"traffic sign\": [],\n",
    "    \"person\": [],\n",
    "    \"car\": [],\n",
    "    \"bicycle\": [],\n",
    "    \"average\": []\n",
    "    }\n",
    "    \n",
    "    for el in validation_ious:\n",
    "        iou_dict[\"building\"].append(el[11].item())\n",
    "        iou_dict[\"traffic sign\"].append(el[20].item())\n",
    "        iou_dict[\"person\"].append(el[24].item())\n",
    "        iou_dict[\"car\"].append(el[26].item())\n",
    "        iou_dict[\"bicycle\"].append(el[33].item())\n",
    "        iou_dict[\"average\"].append(MeanIOU(el))\n",
    "        \n",
    "    iou_df = pd.DataFrame(iou_dict)\n",
    "    \n",
    "    # Plot IoUs\n",
    "    fig,ax = plt.subplots(figsize=(6,5))\n",
    "    ax.set_ylabel('IoUs')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    _=ax.plot(iou_df)\n",
    "    plt.legend(labels=iou_df.columns)\n",
    "    plt.title(\"Specific IoUs over Epochs\")\n",
    "    plt.savefig(join(saving_directory, '{}_IoU.png'.format(best_model_name)))\n",
    "    \n",
    "    # Add losses and accuracies\n",
    "    iou_df['training_losses'] = training_losses\n",
    "    iou_df['training_accuracy'] = training_accuracies\n",
    "    iou_df['validation_losses'] = validation_losses\n",
    "    iou_df['validation_accuracy'] = validation_accuracies\n",
    "    \n",
    "    # Save a csv\n",
    "    iou_df.to_csv(join(saving_directory, '{}.csv'.format(best_model_name)))\n",
    "    \n",
    "    # Test image with overlayed classified labels\n",
    "    test_model = TransResNet(n_class=n_class, base_model=res_type)\n",
    "    test_model.load_state_dict(torch.load(join(saving_directory, '{}.pt'.format(best_model_name))))\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        test_image = sample_batched[0]\n",
    "        break\n",
    "        \n",
    "    test_output = test_model(test_image)\n",
    "    log_output = F.softmax(test_output, dim = 1)\n",
    "    out_labels = torch.argmax(log_output, dim = 1).squeeze().numpy()\n",
    "    test_img_np = data2img(test_image.squeeze(0))\n",
    "    image_overlay(test_img_np, out_labels, join(saving_directory, '{}_ovelayed.png'.format(best_model_name)), n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
